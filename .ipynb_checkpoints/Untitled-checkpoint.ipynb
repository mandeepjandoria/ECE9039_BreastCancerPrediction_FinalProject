{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import operator\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************************************************Feature Selection Method************************************************\n",
    "def correlation_filter(data_duplicate, threshold):\n",
    "    \"\"\"\n",
    "    :param data_duplicate : copied version of the original data-set containing the features of the cancerous and non cancerous cells\n",
    "    :param threshold : parameter around which the non correlated and highly correlated features are distinguished.\n",
    "    :return data_duplicate : new data-set which has only the filtered non correlated features\n",
    "\n",
    "    \"\"\"\n",
    "    col_corr = set()  # Set of all the names of deleted columns\n",
    "    corr_matrix = data_duplicate.corr()\n",
    "    # Loop through the data to remove those corelation values less than the threshold\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in data_duplicate.columns:\n",
    "                    del data_duplicate[colname]  # deleting the column from the dataset\n",
    "\n",
    "    corr_matrix_newdata = data_duplicate.corr()\n",
    "    attribute_names_newdata = corr_matrix_newdata.columns.tolist()\n",
    "    #Figure to see the heatmap of filtered features\n",
    "    figure_2 = plt.figure(figsize=(5, 5))\n",
    "    plt.title('Correlation between reduced features', fontsize=20)\n",
    "    new_feature_data = sns.heatmap(corr_matrix_newdata, vmin=0, vmax=1, annot=True, annot_kws={\"size\": 6}, fmt='.2g',\n",
    "                                   cmap='PiYG',\n",
    "                                   linewidth=2, linecolor='black', cbar='True', xticklabels=attribute_names_newdata,\n",
    "                                   yticklabels=attribute_names_newdata)\n",
    "    new_feature_data.set_xticklabels(\n",
    "        new_feature_data.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        horizontalalignment='right',\n",
    "        fontweight='light',\n",
    "        fontsize=7)\n",
    "    new_feature_data.set_yticklabels(\n",
    "        new_feature_data.get_yticklabels(),\n",
    "        fontweight='light',\n",
    "        fontsize=7)\n",
    "    x, y = plt.ylim()  # get the values for bottom and top\n",
    "    x += 0.75  # Add 0.5 to the bottom\n",
    "    y -= 0.75  # Subtract 0.5 from the top\n",
    "    plt.ylim(x, y)\n",
    "    plt.show()\n",
    "    # saving image in the give path\n",
    "    figure_2.savefig(r'C:\\Users\\Ren\\Desktop\\Test2_heatmap.png')\n",
    "    return data_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************************************************Random Forest Classifier***************************************************\n",
    "\n",
    "def RandomForest_Classifier(x_train, x_test, y_train, y_test):\n",
    "    # OPTION 1: Using default RF classifier setting\n",
    "    classifier_default = RandomForestClassifier()\n",
    "    accuracy_default = classifier_default.fit(x_train, y_train)\n",
    "    y_pred_default = classifier_default.predict(x_test)\n",
    "    cm_default = confusion_matrix(y_test, y_pred_default)\n",
    "    classifier_default_TP = cm_default[0][0]\n",
    "    classifier_default_TN = cm_default[1][1]\n",
    "    classifier_default_FN = cm_default[1][0]\n",
    "    classifier_default_FP = cm_default[0][1]\n",
    "    classifier_default_Accuracy =(classifier_default_TP + classifier_default_TN) / (classifier_default_TP + classifier_default_TN + classifier_default_FN + classifier_default_FP)\n",
    "    classifier_default_Precision = (classifier_default_TP) / (classifier_default_TP + classifier_default_FP)\n",
    "\n",
    "    RFC_Parameter_Tuning = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                                            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                                            min_impurity_split=None, min_samples_leaf=2,\n",
    "                                            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                            n_jobs=None, oob_score=False, random_state=None,\n",
    "                                            n_estimators=10, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "    RFC_Parameter_Tuning_Fit = RFC_Parameter_Tuning.fit(x_train, y_train)\n",
    "    RFC_Parameter_Tuning_Y_Pred = RFC_Parameter_Tuning.predict(x_test)\n",
    "    RFC_Parameter_Tuning_CM = confusion_matrix(y_test, RFC_Parameter_Tuning_Y_Pred)\n",
    "    RFC_Parameter_Tuning_TP = RFC_Parameter_Tuning_CM[0][0]\n",
    "    RFC_Parameter_Tuning_TN = RFC_Parameter_Tuning_CM[1][1]\n",
    "    RFC_Parameter_Tuning_FN = RFC_Parameter_Tuning_CM[1][0]\n",
    "    RFC_Parameter_Tuning_FP = RFC_Parameter_Tuning_CM[0][1]\n",
    "\n",
    "    RFC_Parameter_Tuning_Accuracy = (RFC_Parameter_Tuning_TP + RFC_Parameter_Tuning_TN) / (RFC_Parameter_Tuning_TP + RFC_Parameter_Tuning_TN + RFC_Parameter_Tuning_FN + RFC_Parameter_Tuning_FP)\n",
    "    RFC_Parameter_Tuning_Precision =(RFC_Parameter_Tuning_TP) / (RFC_Parameter_Tuning_TP + RFC_Parameter_Tuning_FP)\n",
    "\n",
    "\n",
    "    Dictionary2 = {}\n",
    "    Dictionary2[\"Default\"] = classifier_default_Accuracy\n",
    "    Dictionary2[\"Parameter_Tuning\"] = RFC_Parameter_Tuning_Accuracy\n",
    "\n",
    "    import operator\n",
    "    a = max(Dictionary2.items(), key=operator.itemgetter(1))[0]\n",
    "    print(\"\\nConfusion Matrix for RFC\\n\", RFC_Parameter_Tuning_CM)\n",
    "    plt.title('Plot showing the accuracy for each Options of RFC')\n",
    "    plt.bar(range(len(Dictionary2)), list(Dictionary2.values()), align='center')\n",
    "    plt.xticks(range(len(Dictionary2)), list(Dictionary2.keys()))\n",
    "    plt.xlabel('Different Options used in Random Forest Classifier')\n",
    "    plt.ylabel(' Accuracy')\n",
    "    plt.show()\n",
    "    sns.heatmap(RFC_Parameter_Tuning_CM, annot=True, cmap='YlOrRd')\n",
    "    plt.title('Confusion Matrix for Random Forest Classifier', fontsize=20)\n",
    "    x, y = plt.ylim()  # get the values for bottom and top\n",
    "    x += 0.75  # Add 0.5 to the bottom\n",
    "    y -= 0.75  # Subtract 0.5 from the top\n",
    "    plt.ylim(x, y)\n",
    "    plt.show()\n",
    "    return Dictionary2[a],RFC_Parameter_Tuning_Precision,a,RFC_Parameter_Tuning_CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********************************************************SVM***************************************************************\n",
    "def KSVM_Classifier(X_train, X_test, y_train, y_test):\n",
    "\n",
    "   # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=0)\n",
    "    SVC_RBF = SVC(kernel='rbf')\n",
    "    SVC_RBF.fit(X_train,y_train)\n",
    "    SVC_RBF_Y_Pred = SVC_RBF.predict(X_test)\n",
    "    SVC_RBF_cm = (confusion_matrix(y_test, SVC_RBF_Y_Pred))\n",
    "    SVC_RBF_TP = SVC_RBF_cm[0][0]\n",
    "    SVC_RBF_TN = SVC_RBF_cm[1][1]\n",
    "    SVC_RBF_FN = SVC_RBF_cm[1][0]\n",
    "    SVC_RBF_FP = SVC_RBF_cm[0][1]\n",
    "    SVC_RBF_accuracy = float(SVC_RBF_cm.diagonal().sum()) / len(y_test)\n",
    "    SVC_RBF_Precision = (SVC_RBF_TP) / (SVC_RBF_TP + SVC_RBF_FP)\n",
    "\n",
    "    SVC_poly = SVC(kernel='poly', degree=8)\n",
    "    SVC_poly.fit(X_train,y_train)\n",
    "    SVC_poly_Y_Pred = SVC_poly.predict(X_test)\n",
    "\n",
    "    SVC_poly_cm = (confusion_matrix(y_test, SVC_poly_Y_Pred))\n",
    "    SVC_poly_accuracy = float(SVC_poly_cm.diagonal().sum()) / len(y_test)\n",
    "    #print(\"Accuracy using Polynomial kernel:\", accuracy_poly)\n",
    "    SVC_poly_TP = SVC_poly_cm[0][0]\n",
    "    SVC_poly_TN = SVC_poly_cm[1][1]\n",
    "    SVC_poly_FN = SVC_poly_cm[1][0]\n",
    "    SVC_poly_FP = SVC_poly_cm[0][1]\n",
    "    SVC_poly_Precision = (SVC_poly_TP) / (SVC_poly_TP + SVC_poly_FP)\n",
    "\n",
    "    SVC_sig = SVC(kernel='sigmoid')\n",
    "    SVC_sig.fit(X_train,y_train)\n",
    "    SVC_sig_Y_Pred = SVC_sig.predict(X_test)\n",
    "    SVC_sig_cm = (confusion_matrix(y_test, SVC_sig_Y_Pred))\n",
    "    SVC_sig_accuracy = float(SVC_sig_cm.diagonal().sum()) / len(y_test)\n",
    "    SVC_sig_TP = SVC_sig_cm[0][0]\n",
    "    SVC_sig_TN = SVC_sig_cm[1][1]\n",
    "    SVC_sig_FN = SVC_sig_cm[1][0]\n",
    "    SVC_sig_FP = SVC_sig_cm[0][1]\n",
    "    SVC_sig_Precision = (SVC_sig_TP) / (SVC_sig_TP + SVC_sig_FP)\n",
    "\n",
    "    Dictionary1 = {}\n",
    "    Dictionary1[\"rbf\"] = SVC_RBF_accuracy\n",
    "    Dictionary1[\"sigmoid\"] = SVC_sig_accuracy\n",
    "    Dictionary1[\"poly\"] = SVC_poly_accuracy\n",
    "\n",
    "    SVC_max_accuracy = max(Dictionary1.items(), key=operator.itemgetter(1))[0]\n",
    "    print(\"\\nConfusion matrix for kSVM\\n \",SVC_RBF_cm )\n",
    "    plt.title('Plot showing the accuracy for each kernal model')\n",
    "    plt.bar(range(len(Dictionary1)), list(Dictionary1.values()), align='center')\n",
    "    plt.xticks(range(len(Dictionary1)), list(Dictionary1.keys()))\n",
    "    plt.xlabel('Different Kernels used in SVM')\n",
    "    plt.ylabel(' Accuracy')\n",
    "    plt.show()\n",
    "    sns.heatmap(SVC_RBF_cm, annot=True, cmap='YlOrRd')\n",
    "    plt.title('Confusion Matrix for KSVM', fontsize=20)\n",
    "    x, y = plt.ylim()  # get the values for bottom and top\n",
    "    x += 0.75  # Add 0.5 to the bottom\n",
    "    y -= 0.75  # Subtract 0.5 from the top\n",
    "    plt.ylim(x, y)\n",
    "    plt.show()\n",
    "    return Dictionary1[SVC_max_accuracy],SVC_RBF_Precision,SVC_max_accuracy,SVC_RBF_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-205f8b415f8e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-205f8b415f8e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    **********************************************************KNN**************************************************************\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#**********************************************************KNN**************************************************************\n",
    "def KNN_Classifier(x_train, x_test, y_train, y_test):\n",
    "\n",
    "\n",
    "    # using knn classifier to predict the data\n",
    "    kneighbors_knn = []\n",
    "    cross_validate_knn_scores = []\n",
    "    cross_validate_knn_scores_2 = []\n",
    "    cross_validate_knn_scores_3 = []\n",
    "    score_knn = []\n",
    "    accuracy_knn = []\n",
    "    confusion_mat_knn = []\n",
    "    knn_y_prediction = []\n",
    "\n",
    "    \"\"\"\n",
    "    The below for loop is used  to find the best value of 'K' neighbour for the dataset. \n",
    "    This is done by finding the accuracy of the classifier at different values of K and then cross validating it.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(1, 50, 2):\n",
    "        # applying classifier at different i\n",
    "        kneighbors_knn.append(i)\n",
    "        knn_1 = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn_1.fit(x_train, y_train)\n",
    "        predict_knn_1 = knn_1.predict(x_test)\n",
    "        knn_y_prediction.append(predict_knn_1)\n",
    "\n",
    "        # finding the accuracy of the classifier each time the vlaue of i/K neighbour changes.\n",
    "        accuracy_knn.append(accuracy_score(y_test, knn_1.predict(x_test)))\n",
    "        scorees = knn_1.score(x_test, y_test)\n",
    "\n",
    "        # Using confusion matrix to observe the falseness and correctness of the predicted results\n",
    "        cm = confusion_matrix(y_test, predict_knn_1)\n",
    "        # storing different confusion matrix in one list\n",
    "        confusion_mat_knn.append(cm)\n",
    "        score_knn.append(scorees)\n",
    "\n",
    "        # cross validate the correct value of k\n",
    "        scores = cross_val_score(knn_1, x_train, y_train, cv=10, scoring='accuracy')\n",
    "        cross_validate_knn_scores.append(scores.mean())\n",
    "        scores_2 = cross_val_score(knn_1, x_train, y_train, cv=15, scoring='accuracy')\n",
    "        cross_validate_knn_scores_2.append(scores_2.mean())\n",
    "        scores_3 = cross_val_score(knn_1, x_train, y_train, cv=20, scoring='accuracy')\n",
    "        cross_validate_knn_scores_3.append(scores_3.mean())\n",
    "\n",
    "    \"\"\"\n",
    "        in the below output the K value for cross validtion is same at K=3,7,13. Hence we can choose any one for the value of K.\n",
    "        When we further change the cv to 15, we get K=13 again.Hence showing that K at 13 is correct value.\n",
    "\n",
    "    \"\"\"\n",
    "    knn_range = range(1, 50, 2)\n",
    "    figure_4 = plt.figure(figsize=(5, 5))\n",
    "    plt.title('Relation between K and corresponding accuracy of KNN model', fontsize=20)\n",
    "    plt.plot(knn_range, accuracy_knn,color='#4b0082')\n",
    "    plt.xlabel('Value of K for KNN')\n",
    "    plt.ylabel(' Accuracy')\n",
    "    #plt.show()\n",
    "    plt.savefig(r'C:\\Users\\Ren\\Desktop\\Test2_fig5_accuracy.png')\n",
    "    c = ((accuracy_knn.index(max(accuracy_knn))) * 2) + 1\n",
    "    KNN_Classifier_Cancer = KNeighborsClassifier(n_neighbors=c, metric='minkowski', p=2)\n",
    "    KNN_Classifier_Cancer.fit(x_train, y_train)\n",
    "    KNN_y_pred = KNN_Classifier_Cancer.predict(x_test)\n",
    "    score_Knn_cancer = KNN_Classifier_Cancer.score(x_test, y_test)\n",
    "\n",
    "    KNN_Confusion_Matrix = confusion_matrix(y_test,KNN_y_pred)\n",
    "    print('\\nConfusion Matrix for KNN\\n', KNN_Confusion_Matrix)\n",
    "    KNN_True_Positive = KNN_Confusion_Matrix[0][0]\n",
    "    KNN_True_Negative = KNN_Confusion_Matrix[1][1]\n",
    "    KNN_False_Positive = KNN_Confusion_Matrix[0][1]\n",
    "    KNN_False_Negative = KNN_Confusion_Matrix[1][0]\n",
    "\n",
    "    KNN_accuracy = (KNN_True_Positive + KNN_True_Negative) / (KNN_True_Positive + KNN_True_Negative + KNN_False_Positive + KNN_False_Negative)\n",
    "    precision_knn =KNN_True_Positive / (KNN_True_Positive + KNN_False_Positive)\n",
    "\n",
    "    figure_5 = plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(KNN_Confusion_Matrix, annot=True, cmap='YlOrRd')\n",
    "    plt.title('Confusion Matrix for KNN Classifier', fontsize=20)\n",
    "    x, y = plt.ylim()  # get the values for bottom and top\n",
    "    x += 0.75  # Add 0.5 to the bottom\n",
    "    y -= 0.75  # Subtract 0.5 from the top\n",
    "    plt.ylim(x, y)\n",
    "    plt.show()\n",
    "    figure_5 = plt.savefig(r'C:\\Users\\Ren\\Desktop\\Test2_fig6_knn_confusionMatrix.png')\n",
    "    return KNN_accuracy,precision_knn,c,KNN_Confusion_Matrix\n",
    "\n",
    "def SVM_Classifier(X_train, X_test, y_train, y_test):\n",
    "    # Linear Kernel\n",
    "    SVM_Classifier = svm.SVC(kernel='linear')\n",
    "    # Training the model using the training sets\n",
    "    SVM_Classifier.fit(X_train, y_train)\n",
    "    # Predicting the response for test sets\n",
    "    SVM_Classifier_Y_Pred = SVM_Classifier.predict(X_test)\n",
    "    # Evaluating the model\n",
    "    SVM_Classifier_CM = (confusion_matrix(y_test, SVM_Classifier_Y_Pred))\n",
    "    SVM_Classifier_accuracy = float(SVM_Classifier_CM.diagonal().sum()) / len(y_test)\n",
    "    sns.heatmap(SVM_Classifier_CM, annot=True, cmap='YlOrRd')\n",
    "    plt.title('Confusion Matrix for SVM', fontsize=20)\n",
    "    x, y = plt.ylim()  # get the values for bottom and top\n",
    "    x += 0.75  # Add 0.5 to the bottom\n",
    "    y -= 0.75  # Subtract 0.5 from the top\n",
    "    plt.ylim(x, y)\n",
    "    plt.show()\n",
    "    # Import scikit-learn metrics module for accuracy calculation\n",
    "    from sklearn import metrics\n",
    "    # Calculating the model accuracy to check how often classifier is correct\n",
    "    print(\"\\nConfusion Matrix for SVM \\n\",SVM_Classifier_CM)\n",
    "\n",
    "    return SVM_Classifier_accuracy,metrics.precision_score(y_test, SVM_Classifier_Y_Pred),\"Linear\",SVM_Classifier_CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************ReportPrint*************************************************************\n",
    "def Report(list_accuracy):\n",
    "    dash = '-' * 70\n",
    "    for m in range(len(list_accuracy)):\n",
    "        if m == 0:\n",
    "            print(dash)\n",
    "            print('{:<10s}{:>14s}{:>12s}{:>12s}'.format(list_accuracy[m][0], list_accuracy[m][1],\n",
    "                                                              list_accuracy[m][2], list_accuracy[m][3]))\n",
    "            print(dash)\n",
    "        else:\n",
    "            print('{:<10s}{:>15s}{:^22.6f}{:^2.5f}'.format(list_accuracy[m][0], list_accuracy[m][1],\n",
    "                                                                  list_accuracy[m][2],\n",
    "                                                                  list_accuracy[m][3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************Main Code**************************************************\n",
    "# Read the featured dataset\n",
    "Original_Dataset = pd.read_csv('wdbc_data.csv')\n",
    "\n",
    "# drop the ID column from the data-set\n",
    "Original_Dataset=Original_Dataset.drop(['ID'], axis=1)\n",
    "# converting the Categorical values to Binary\n",
    "Original_Dataset['Diagnosis'].replace('B', 0, inplace=True)\n",
    "Original_Dataset['Diagnosis'].replace('M', 1, inplace=True)\n",
    "\n",
    "# creating duplicate copy of the original data-set\n",
    "Original_Dataset_duplicate = Original_Dataset.copy()\n",
    "# finding the correlation between all the features in the data-set 1 or the original data-set\n",
    "correlation_ds1 = Original_Dataset.corr()\n",
    "attribute_names = correlation_ds1.columns.tolist()\n",
    "# figure_1 represents the heatmap version of the correlation between all the features in the data-set\n",
    "Figure_1 = plt.figure(figsize=(60, 60))\n",
    "Figure_1.suptitle('Correlation between all the features', fontsize=10)\n",
    "# plotting heatmap between the features by passing the correlated values of the features to the heatmap\n",
    "Feature_correlation_ds1 = sns.heatmap(correlation_ds1,\n",
    "                                      vmin=0, vmax=1, annot=True, annot_kws={\"size\": 6}, fmt='.2g',\n",
    "                                      cmap='winter', linewidth=2, linecolor='black', cbar='True',\n",
    "                                      xticklabels=attribute_names, yticklabels=attribute_names)\n",
    "Feature_correlation_ds1.set_xticklabels(\n",
    "    Feature_correlation_ds1.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right',\n",
    "    fontweight='light',\n",
    "    fontsize=7)\n",
    "Feature_correlation_ds1.set_yticklabels(\n",
    "    Feature_correlation_ds1.get_yticklabels(),\n",
    "    fontweight='light',\n",
    "    fontsize=7)\n",
    "b, t = plt.ylim()  # getting data of the bottom and top of the matrix frame\n",
    "b += 0.75  # adjusting the bottom range so that the data is not displayed out of the matrix size\n",
    "t -= 0.75  # adjusting the top range so that the data is not displayed out of the matrix size\n",
    "plt.ylim(b, t)\n",
    "plt.show()\n",
    "# saving image in the given path\n",
    "Figure_1.savefig(r'C:\\Users\\Ren\\Desktop\\Test2_fig1_th55.png')\n",
    "\n",
    "# calling function which will filter the dataset and eliminate highly correlated features based on the input threshold value\n",
    "Filtered_Dataset = correlation_filter(Original_Dataset_duplicate, 0.55)\n",
    "\n",
    "# saving the filtered data-set as excel format\n",
    "Filtered_Dataset.to_csv(r'C:\\Users\\Ren\\Desktop\\Test3_filtered_hm.csv')\n",
    "\n",
    "\n",
    "# Filter_data2 and Filtered_Dataset contains reduced parameters\n",
    "filtered_dataset = pd.read_csv(r'C:\\Users\\Ren\\Desktop\\Test3_filtered_hm.csv')\n",
    "\n",
    "\n",
    "# splitting dataset into features and output\n",
    "features_data = filtered_dataset.iloc[:, 2:10]\n",
    "output_data = filtered_dataset.iloc[:, 1]\n",
    "\n",
    "# Split the features_data and output_data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_data,output_data, test_size=0.30, random_state=0)\n",
    "\n",
    "scale_data = StandardScaler()\n",
    "X_train = scale_data.fit_transform(X_train)\n",
    "X_test = scale_data.transform(X_test)\n",
    "#calling knn classifier\n",
    "\n",
    "CM_KNN= []\n",
    "CM_SVM= []\n",
    "CM_KSVM= []\n",
    "CM_RFC= []\n",
    "#calling knn classifier\n",
    "Accuracy_KNN,Precision_KNN,Parameter_KNN,CM_KNN= KNN_Classifier(X_train, X_test, y_train, y_test)\n",
    "#calling SVM classifier\n",
    "Accuracy_SVM,Precision_SVM,Parameter_SVM,CM_SVM= SVM_Classifier(X_train, X_test, y_train, y_test)\n",
    "#calling kSVM classifier\n",
    "Accuracy_KSVM,Precision_KSVM,Parameter_KSVM,CM_KSVM= KSVM_Classifier(X_train, X_test, y_train, y_test)\n",
    "#calling RFC classifier\n",
    "Accuracy_RFC,Precision_RFC,Parameter_RFC,CM_RFC= RandomForest_Classifier(X_train, X_test, y_train, y_test)\n",
    "\n",
    "list_accuracy=[['Classifier_Name','Parameter/Method','Accuracy','Precision'],['SVM','Kernel='+str(Parameter_KSVM),Accuracy_KSVM,Precision_KSVM],['KNN','K='+str(Parameter_KNN),Accuracy_KNN,Precision_KNN],['RFC','K='+str(Parameter_RFC),Accuracy_RFC,Precision_RFC],['SVM','K='+str(Parameter_SVM),Accuracy_SVM,Precision_SVM]]\n",
    "\n",
    "Report(list_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
